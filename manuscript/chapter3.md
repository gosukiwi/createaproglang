# Parsing
Parsing or semantic analysis is what gives meaning to a bunch of tokens. What 
does an identifier followed by an equal, followed by a number means (a = 1)? 
Most likely it means an assignment, the output of a parser is a tree, called 
Abstract Syntax Tree.

![How a lexer works](images/ch1-parser.png)

Using the same tokens from the example above, the parser process would look 
somethig like this

    INPUT:
    [('identifier', 'name'), ('equal'), ('string', 'mike')]
    
    OUTPUT:
    [('assign', ('variable', ('identifier', 'name')), ('value', ('string', 'mike')))]

The output is a tree represented as a nested array, it might be hard to see,
but it's just a regular tree, like a genealogical tree!

![How a lexer works](images/ch1-ast.png)

You can see an `assign` node has two children, an identifier and a value, this 
is a syntax rule, which might be defined as follows using the 
[BNF](http://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form):

    assign ::= identifier equal expression
    expression ::= string | number

BNF is just a way to represent a context-free grammar, we'll talk more about it
later, for now, just know that we can define how the tokens will be organized
by using rules. The left side of the `::=` is the name of the rule, and
the right side is the value, the `|` means _or_, just knowing that we can 
deduce an `assign` rule is composed of an identifier, an equal, and an
expression, which can be either a string or a number.

These rules are really useful when we want to define how our language must
be structured, and we can even throw significant _Syntax Errors_.

## Interpreting / Code Generation
So far so good, we have our pretty and shiny AST, but what do we do with it?
Well we have two choices, the first one is generating code in another language.
most of the time a lower-level language but it can be anything you want. An
example of code generation is the CoffeeScript compiler, which takes a
CoffeeScript program as input, and outputs a valid Javascript program. Another
example is GCC, a compiler which takes C code as input and outputs highly
optimized assembly code, this is why C is known as one of the fastests languages
out there, if not the fastest.

The second thing we can do with out AST is interpret it, this is what languages
such as Ruby and PHP do. For example the original Ruby interpreter, it's a C
program which takes a Ruby program as input, and outputs a value by evaluating
that code. The speed at which interpreted language performs computations is
highly dependant on the language it's implemented, that's why most interpreters
out there are in C.

A compiler and an interpreter are two very different beasts, and depending on
the language mission you should choose one or the other. In this book we'll
write a compiler, but it's possible to reuse the topics discussed here as a good
base to write an interpreter, the only thing that changes is what you do with th
AST.

There's something very important to note though, there's an intermediate point
between compiled languages and interpreted languages, which is where Virtual
Machines come along. Java is a good example, the Java compiler takes the Java
source code, and _compiles_ it to Java bytecode, which is another language much
simpler than Java, it's this compiled code the one that gets executed by an
interpreter, in this case a Virtual Machine or VM. Why do this? Well by
interpreting a reduced set of instructions the performance of the language can
increase significantly, also it allows for the generated bytecode to be
platform-agnostic, meaning it can run on any platform as long as that platform
has a working VM.

It's possible to make a language which targets an specific VM, such as the Java
VM or .NET's CLR. That way you take advantage of the huge effor put in those
interpreters to make your code fly!

## Our First Parser
Before we dive right in, let's see what we'll build. There are several ways to
write parsers, each has it's own advantages and disadvantages, for our first
parser we'll use the easiest to implement, and also the most commonly used, it's
called a Recursive Descent Parser, according to Wikipedia:

 > In computer science, a recursive descent parser is a kind of top-down
 > parser built from a set of mutually recursive procedures (or a 
 > non-recursive equivalent) where each such procedure usually implements one
 > of the production rules of the grammar. Thus the structure of the resulting
 > program closely mirrors that of the grammar it recognizes.

Summing it up, a grammar is just a set of rules which describe the syntax or a
language; A Recursive Descent Parser is bunch of functions which might call
themselves, and each function is in charge of recognizing a rule in a that of
grammar. 

Don't worry much about the grammars, it's good to play around with them and know
what they are, but it's not really needed for the practical purposes of this
book. If you want to know more about grammars and the theorical aspect of
parsing you can see [Marc Moreno Maza's
document](http://www.csd.uwo.ca/~moreno//CS447/Lectures/Syntax.html/Syntax.html)
on the matter.
