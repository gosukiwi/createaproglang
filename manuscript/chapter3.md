# Parsing
Parsing or semantic analysis is what gives meaning to a bunch of tokens. What 
does an identifier followed by an equal, followed by a number means (a = 1)? 
Most likely it means an assignment, the output of a parser is a tree, called 
Abstract Syntax Tree.

![How a lexer works](images/ch1-parser.png)

Using the same tokens from the example above, the parser process would look 
somethig like this

    INPUT:
    [('identifier', 'name'), ('equal'), ('string', 'mike')]
    
    OUTPUT:
    [('assign', ('variable', ('identifier', 'name')), ('value', ('string', 'mike')))]

The output is a tree represented as a nested array, it might be hard to see,
but it's just a regular tree, like a genealogical tree!

![How a lexer works](images/ch1-ast.png)

You can see an `assign` node has two children, an identifier and a value, this 
is a syntax rule, which might be defined as follows using the 
[BNF](http://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form):

    assign ::= identifier equal expression
    expression ::= string | number

BNF is just a way to represent a context-free grammar, we'll talk more about it
later, for now, just know that we can define how the tokens will be organized
by using rules. The left side of the `::=` is the name of the rule, and
the right side is the value, the `|` means _or_, just knowing that we can 
deduce an `assign` rule is composed of an identifier, an equal, and an
expression, which can be either a string or a number.

These rules are really useful when we want to define how our language must
be structured, and we can even throw significant _Syntax Errors_.

## Interpreting / Code Generation
So far so good, we have our pretty and shiny AST, but what do we do with it?
Well we have two choices, the first one is generating code in another language.
most of the time a lower-level language but it can be anything you want. An
example of code generation is the CoffeeScript compiler, which takes a
CoffeeScript program as input, and outputs a valid Javascript program. Another
example is GCC, a compiler which takes C code as input and outputs highly
optimized assembly code, this is why C is known as one of the fastests languages
out there, if not the fastest.

The second thing we can do with out AST is interpret it, this is what languages
such as Ruby and PHP do. For example the original Ruby interpreter, it's a C
program which takes a Ruby program as input, and outputs a value by evaluating
that code. The speed at which interpreted language performs computations is
highly dependant on the language it's implemented, that's why most interpreters
out there are in C.

A compiler and an interpreter are two very different beasts, and depending on
the language mission you should choose one or the other. In this book we'll
write a compiler, but it's possible to reuse the topics discussed here as a good
base to write an interpreter, the only thing that changes is what you do with th
AST.

There's something very important to note though, there's an intermediate point
between compiled languages and interpreted languages, which is where Virtual
Machines come along. Java is a good example, the Java compiler takes the Java
source code, and _compiles_ it to Java bytecode, which is another language much
simpler than Java, it's this compiled code the one that gets executed by an
interpreter, in this case a Virtual Machine or VM. Why do this? Well by
interpreting a reduced set of instructions the performance of the language can
increase significantly, also it allows for the generated bytecode to be
platform-agnostic, meaning it can run on any platform as long as that platform
has a working VM.

It's possible to make a language which targets an specific VM, such as the Java
VM or .NET's CLR. That way you take advantage of the huge effor put in those
interpreters to make your code fly!

## Meet URYB our toy language

The language we'll create looks pretty much like ruby, but simpler. Let's call
it _URYB_. Here's how it looks like:

    # comments use hashes
    a = 2 #assignment

    # function definition
    def add(a, b)
        return a + b
    end

    # conditional
    if a == 2
        print "a is 2"
    end

    # while loop
    while a < 5
        a = a + 1
    end

So far we'll only work on this, we'll add more features later on, feel free to
change anything you want! That's the point of creating your very own programming
language!

## Our First Parser
Let's get down to bussiness and start writing some code! There are several ways
to write parsers, each has it's own advantages and disadvantages, for our first
parser we'll use the easiest to implement, and also the most commonly used, 
it's called a Recursive Descent Parser, according to Wikipedia:

 > In computer science, a recursive descent parser is a kind of top-down
 > parser built from a set of mutually recursive procedures (or a 
 > non-recursive equivalent) where each such procedure usually implements one
 > of the production rules of the grammar. Thus the structure of the resulting
 > program closely mirrors that of the grammar it recognizes.

Summing it up, a Recursive Descent Parser is just a bunch of functions which
might call themselves, and each function is in charge of recognizing a rule in a
special type of grammar called LL(1). Don't worry much about the grammars, allo
you should know is that there are several types of grammars.

### LL(1) Grammars
As stated earlier, recursive descent parsers can only parse a subset of context
free grammars, called LL(1) Grammars, they are just grammars which limit the
format of the rules a bit in order to make it easier to parse.  According to
[Marc Moreno
Maza](http://www.csd.uwo.ca/~moreno//CS447/Lectures/Syntax.html/node14.html):

> The first L stands for scanning the input from left to right
> The second L stands for producing a leftmost derivation
> And the 1 stands for using one input symbol of lookahead at each step to make parsing action decision.
> 
> [...] It can be shown that LL(1) grammars are
>  * Not ambiguous and
>  * Not left-recursive.

There are rules to convert a CF grammar to a LL grammar, so we can parse
anything a CF grammar can, we just have to adjust the rules. We won't get into
many theorical details, if you want to know more about grammars you can see
[Marc Moreno Maza's
document](http://www.csd.uwo.ca/~moreno//CS447/Lectures/Syntax.html/Syntax.html)
on the matter.
